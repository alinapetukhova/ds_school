{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport scipy\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport graphviz\nfrom matplotlib import pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.ensemble import VotingClassifier\n\npd.set_option('display.max_rows', 200)",
      "execution_count": 243,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df=pd.read_excel(\"../input/data2.xlsx\")",
      "execution_count": 244,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "76c4e697d59046c40eebddfb37861c45f39f5594"
      },
      "cell_type": "markdown",
      "source": "Normalize features using Yeo-Johnson transformation, because df contains negative values. Other transformations (aside from quantile, which just makes anything normal, but is non-linear) had far less effect on outliers. Still the distribution is not normal, but it should be enough for classification algorithms."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e909c5c64b7768a83debd5cd6863829e49b51d2a"
      },
      "cell_type": "code",
      "source": "x = list(df.columns.values)\nx.remove('Country Name')\ndf2 = df.copy()\nmapper = DataFrameMapper([(df2[x].columns, PowerTransformer())])\ndf2[x] = mapper.fit_transform(df2[x])",
      "execution_count": 245,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ddb90b9d9346140d0fa76ebb98ea9b5f8d333f5"
      },
      "cell_type": "code",
      "source": "df2[\"LE > median\"]=df2[\"Life expectancy\"].apply(lambda x: 1 if (x>(np.median(df2[\"Life expectancy\"]))) else 0)\nX_train, X_test, Y_train, Y_test = train_test_split(df2.drop(labels=['Country Name', 'Life expectancy', 'LE > median'], axis = 1),\n                                                    df2['LE > median'], test_size=0.25, random_state=17, shuffle=True)",
      "execution_count": 246,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b7c7e5c18e7c35c2999a4f82e2a02dddcdbe94e5"
      },
      "cell_type": "markdown",
      "source": "Bagging (decision trees)"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "16c02794fa9a688a4a632f07e0fe077552496ee7"
      },
      "cell_type": "code",
      "source": "treeBag = BaggingClassifier(DecisionTreeClassifier(random_state=17),n_estimators=200, random_state=17)\ntreeBag.fit(X_train, Y_train)\nprint(\"training acc \" + str(treeBag.score(X_train, Y_train)))\nprint(\"test acc \" + str(treeBag.score(X_test, Y_test)))\nprint(\"F1-score \" + str(f1_score(Y_test, treeBag.predict(X_test))))\nprint(\"ROC AUC \" + str(roc_auc_score(Y_test, treeBag.predict(X_test))))\nprint(\"Matthews correlation coefficient \" + str((matthews_corrcoef(Y_test, treeBag.predict(X_test))+1)/2))",
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": "training acc 1.0\ntest acc 0.9716713881019831\nF1-score 0.9719887955182073\nROC AUC 0.9716383772721802\nMatthews correlation coefficient 0.9716989500245858\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "55c4eb5c056bf99a6c83fac52d8dbfb9336ac8d1"
      },
      "cell_type": "markdown",
      "source": "The dataset is balanced and 0 and 1 have equal value, so all metrics give similar values. MCC is corrected because it has values [-1 ; +1]. The main accuracy metric for this dataset will be a simple accuracy score."
    },
    {
      "metadata": {
        "_uuid": "0d7514355d38c73eb858bee9a396ab630313d7e2"
      },
      "cell_type": "markdown",
      "source": "Random forest (with features importance)"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "56e46ebd6beac4677f54d8a9dbaef276f19a6d42"
      },
      "cell_type": "code",
      "source": "rfc=RandomForestClassifier(n_estimators=200, random_state=17, n_jobs = -1)\nrfc.fit(X_train, Y_train)\nfor name, importance in zip(X_train.columns, rfc.feature_importances_):\n    print(name, importance)\nprint(\"\")\nprint(\"training acc \" + str(rfc.score(X_train, Y_train)))\nprint(\"test acc \" + str(rfc.score(X_test, Y_test)))",
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Year 0.015958766493153923\nEducation exp. %GNI 0.027260969305166017\nAdolescent fertility rate 0.11603164635956699\nAge dependency ratio 0.17181650637266851\nAgriculture v.add. %GDP 0.1181499905134848\nImmunization, measles 0.0583507199596368\nMobile sub./population 0.03969628351164325\nRural population % 0.08819496964150982\nCereal tn/ha ln 0.08429634714432543\nGDP US$ per capita ln 0.19144888282384825\nGDP US$ ln 0.049793344949270395\nInflation 0.03900157292572559\n\ntraining acc 1.0\ntest acc 0.9730878186968839\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "e28671bac196d95f005d7506bdb52fd7b24d8f73"
      },
      "cell_type": "markdown",
      "source": "Linear classifier"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "ba7b60f939c7ebc78678cf98b65a2a0c5a9f1488"
      },
      "cell_type": "code",
      "source": "log_c = SGDClassifier(loss='log', n_jobs=-1, random_state=17, tol = None, max_iter=1000)\nlog_c.fit(X_train, Y_train)\nprint(\"training acc \" + str(log_c.score(X_train, Y_train)))\nprint(\"test acc \" + str(log_c.score(X_test, Y_test)))",
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": "training acc 0.8761814744801513\ntest acc 0.886685552407932\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce80f2abad07e3978fd1276e5190327a67686b08",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_jobs = -1)\nknn.fit(X_train, Y_train)\nprint(\"training acc \" + str(knn.score(X_train, Y_train)))\nprint(\"test acc \" + str(knn.score(X_test, Y_test)))",
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": "training acc 0.9810964083175804\ntest acc 0.9546742209631728\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "824fcbd3938ebae595a294add0552cbf23d12f60"
      },
      "cell_type": "code",
      "source": "knn_grid = GridSearchCV(KNeighborsClassifier(), param_grid = {'n_neighbors': range(1, 10)}, cv=5)\nknn_grid.fit(X_train, Y_train)\nprint(knn_grid.best_params_)\nprint('training acc ' + str(knn_grid.best_score_))\nprint(\"test acc \" + str(knn_grid.score(X_test, Y_test)))",
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'n_neighbors': 1}\ntraining acc 0.9725897920604915\ntest acc 0.9702549575070821\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "700f3f92d0e66bea25985a1fb1d8f96b3e33e78a"
      },
      "cell_type": "markdown",
      "source": "On 75% training 25% test:\nBest result - random forest, worst - linear classifier, tried with different parameters, didnt manage to get above 0.87 acc.\n\nKNN (k_neighbours = 1, all other parameters dont imporbe the result significantly) has shown the best result on 25% training 75% test dataset with the same parameters."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "7a01590c256eb32ace8f4384633a79091460ebaf"
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_neighbors = 1, n_jobs = -1)\nens1 = VotingClassifier(estimators=[('RFor', rfc), ('KNN', knn), ('Log_c', log_c)], voting='hard', n_jobs = -1)\nens1.fit(X_train, Y_train)\nprint('training acc ' + str(ens1.score(X_train, Y_train)))\nprint(\"test acc \" + str(ens1.score(X_test, Y_test)))",
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": "training acc 1.0\ntest acc 0.9759206798866855\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "0fa64625b98a7f463fe8d338a32f693913a6945a"
      },
      "cell_type": "markdown",
      "source": "The ensemble, despite being very simple, has managed to show better accuracy on the test set than each of the models individually."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}