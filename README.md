# ds_school
test assignments for the data science school - Roonyx

### Assignment 1.

* Choose data set from [Kaggle repo](https://www.kaggle.com/datasets). Data set shouldn't be analysed before in the available tutorials.
* Explore main data set features and target labels. (+ 0.5 score per unique method. Min score 2, Max score 4)
* Feature engineering for the new parameters (+ 1 score per unique feature. Min score 2, Max score 4)
* Choose and display statistics for the observations. In this step you need to create Statistical hypothesis and test them. Hypothesis should be meaningful and display some patterns in the data set (+ 3 score per hypothesis. Min score 6, Max score 12)
* Visualise explored features and hypothesis (+ 1 score per plot. Min score 6, Max score 10)

Useful resources:
- [ODS topic 1](https://www.kaggle.com/kashnitsky/topic-1-exploratory-data-analysis-with-pandas)
- [ODS topic 2.1](https://www.kaggle.com/kashnitsky/topic-2-visual-data-analysis-in-python)
- [ODS topic 2.2](https://www.kaggle.com/kashnitsky/topic-2-part-2-seaborn-and-plotly)

### Assignment 2.

With selected data set:

* Calculate entropy for full data set and for 2 selected groups. What is the information gain for such split? (+2 score)
* Calculate Gini index for the same groups and compare results (+2 score)
* Train a decision tree (DecisionTreeClassifier, random_state = 17) (+2 score) 
* Find the optimal maximum depth using 5-fold cross-validation (GridSearchCV) (+2 score) 
* Display final tree as an image (+2 score)

Useful resources:
- [ODS topic 3.1](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/assignments_demo/assignment03_decision_trees.ipynb?flush_cache=true)
- [Grid search](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html)

### Assignment 3.

With selected data set (if applicable, or change from school repo):

* Create and train BaggingClassifier (+2 score)
* Create and train RandomForestClassifier (+2 score)
* Create and train Linear classifier (+2 score)
* Create and train k Nearest Neighbors classifier (+2 score)
* Compare models accuracy
* Create an ensemble of models and estimate classification accuracy
* Display different accuracy metrics for model (+ 1 score per metric. Min score 2, Max score 4)

### Assignment 4.

With selected data set (if applicable, or change from school repo):

* Create and train BaggingRegressor (+2 score)
* Create and train RandomForestRegressor (+2 score)
* Create and train Logistic Regression model (+2 score)
* Create and train k Nearest Neighbors Regression (+2 score)
* Compare models accuracy
* Create an ensemble of models and estimate classification accuracy
* Display different accuracy metrics for model (+ 1 score per metric. Min score 2, Max score 4)

Useful resources:
- [ODS topic 5.1](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging)
- [ODS topic 5.2](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest)
- [ODS topic 3.2](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-3-classification-decision-trees-and-k-nearest-neighbors-8613c6b6d2cd)
- [ODS topic 4.1](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-1-ols)
- [ODS topic 4.2](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification)
- [ODS topic 4.5](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-5-validation)
- [ODS topic 4.1](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-1-ols)

### Assignment 5.

With selected data set (if applicable, or change from school repo):

* Create and train AdaBoostClassifier (+2 score)
* Create and train XGBoostClassifier (+2 score)
* Create and train LightGBM Classifier (+2 score)
* Create and train CatBoostClassifier (+2 score)
* Compare accuracy for models (+2 score)

## Final Assignments

1. Marketing data (one of the data topic per group): 
 - Upwork analysis 
 - Facebook CTF analysis
2. Face recognition task
 - Emotion recognition
 - Age recognition and gender recognition
 - Pose estimation and motion extraction
3. Sequence models
 - voice timbre detection
 - voice script recognition
 - ??
4. Kaggle competition. Join one of the open competitions and create a kernel.
